{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone\n",
        "!pip install langchain_core\n",
        "!pip install langchain_groq\n",
        "!pip install langgraph\n",
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf08ziBuqGjp",
        "outputId": "a761bc9f-47fd-47ae-8f6b-46f040ddff00",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.8.3)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (0.3.74)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (2.11.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain_core) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain_core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain_core) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain_core) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain_core) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (1.3.1)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.12/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (0.3.74)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (0.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.14.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain_groq) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain_groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain_groq) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain_groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain_groq) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain_groq) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain_groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain_groq) (2.5.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.6)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.74)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.3)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install requests\n",
        "!pip install nest-asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bWF90VNoY1qF",
        "outputId": "2e7eba30-a8bd-4ad2-b142-1d7f86443b1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.116.1)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.47.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jrnjqgAjz3_v",
        "outputId": "dd82a515-034c-4164-e62c-59d274d4ef08"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-18' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n",
            "    self.__step_run_and_handle_result(exc)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n",
            "    self.__step_run_and_handle_result(exc)\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict, Any, TypedDict\n",
        "from pinecone import Pinecone\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_groq import ChatGroq\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain.tools import Tool\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "LghIFH_pdO_8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_KEY')\n",
        "GROQ_API_KEY = userdata.get('GROQ_KEY')\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_KEY')"
      ],
      "metadata": {
        "id": "cRqvWO8attp9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# load embedding model\n",
        "embed_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "Awu9czmO_SBA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PineconeRetriever:\n",
        "    def __init__(self, api_key: str):\n",
        "        self.pc = Pinecone(api_key=api_key)\n",
        "\n",
        "    def retrieve_data(self, index_name: str, namespace: str, query: str, top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"Retrieve data from Pinecone index\"\"\"\n",
        "        try:\n",
        "            # Get index\n",
        "            index = self.pc.Index(index_name)\n",
        "\n",
        "            query_embedding = embed_model.encode(query).tolist()  # convert to list for Pinecone\n",
        "\n",
        "            # For demo purposes, we'll create a simple embedding\n",
        "            # In production, you'd use the same embedding model used for indexing\n",
        "            # Here we'll use a simple query-based retrieval simulation\n",
        "\n",
        "            # Query the index (assuming you have embeddings)\n",
        "            # This is a placeholder - you'll need to generate proper embeddings\n",
        "\n",
        "            print(f\"Retrieving from the index {index_name} and namespace {namespace}\")\n",
        "            results = index.query(\n",
        "                vector=query_embedding,\n",
        "                top_k=top_k,\n",
        "                include_metadata=True,\n",
        "                namespace=namespace\n",
        "            )\n",
        "\n",
        "            retrieved_docs = []\n",
        "            for match in results.matches:\n",
        "                retrieved_docs.append({\n",
        "                    'id': match.id,\n",
        "                    'score': match.score,\n",
        "                    'content': match.metadata.get('chunk_text', ''),\n",
        "                    'file_name': match.metadata.get('file_name', ''),\n",
        "                    'page': match.metadata.get('page', 'N/A'),\n",
        "                    'topic': match.metadata.get('topic', ''),\n",
        "                    'name': match.metadata.get('name', '')\n",
        "                })\n",
        "\n",
        "            return retrieved_docs\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving from Pinecone: {e}\")\n",
        "            return []"
      ],
      "metadata": {
        "id": "k0B2P7xnuHwP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiAgentLLMSystem:\n",
        "    def __init__(self, groq_api_key: str, content_control: Dict):\n",
        "        self.content_control = content_control\n",
        "\n",
        "        # LLM 1: Summarizer - Condenses content with citations\n",
        "        self.summarizer = ChatGroq(\n",
        "            model=\"llama3-8b-8192\",\n",
        "            api_key=groq_api_key,\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "        # LLM 2: Reasoner - Deep analysis with citations\n",
        "        self.reasoner = ChatGroq(\n",
        "            model=\"llama3-70b-8192\",\n",
        "            api_key=groq_api_key,\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        # LLM 3: Stylist - Final formatting with citations\n",
        "        self.stylist = ChatGroq(\n",
        "            model=\"llama3-8b-8192\",\n",
        "            api_key=groq_api_key,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        # Main Agent: Orchestrates everything\n",
        "        self.main_agent = ChatGroq(\n",
        "            model=\"llama3-70b-8192\",\n",
        "            api_key=groq_api_key,\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "    def create_citation(self, metadata: Dict) -> str:\n",
        "        \"\"\"Create standardized citation format\"\"\"\n",
        "        file_name = metadata.get('file_name', 'Unknown')\n",
        "        page = metadata.get('page', 'N/A')\n",
        "        topic = metadata.get('topic', '')\n",
        "\n",
        "        citation = f\"[Source: {file_name}, Page: {int(page)}\"\n",
        "        if topic:\n",
        "            citation += f\", Topic: {topic}\"\n",
        "        citation += \"]\"\n",
        "\n",
        "        return citation\n",
        "\n",
        "    def llm1_summarizer(self, content: str, metadata: Dict, length_control: str) -> str:\n",
        "        \"\"\"LLM 1: Summarizer with length control\"\"\"\n",
        "        citation = self.create_citation(metadata)\n",
        "\n",
        "        length_instructions = {\n",
        "            \"short\": \"Summarize in exactly 1-2 sentences\",\n",
        "            \"medium\": \"Summarize in exactly 3-4 sentences\",\n",
        "            \"long\": \"Summarize in exactly 1 paragraph (5-6 sentences)\"\n",
        "        }\n",
        "\n",
        "        length_instruction = length_instructions.get(length_control, length_instructions[\"short\"])\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are LLM Agent 1 - Medical Content Summarizer.\n",
        "\n",
        "        Task: {length_instruction} while preserving key medical information.\n",
        "\n",
        "        CRITICAL RULES:\n",
        "        1. {length_instruction}\n",
        "        2. Always end with this exact citation: {citation}\n",
        "        3. Focus on most important medical facts only\n",
        "        4. Use clear, precise language\n",
        "\n",
        "        Content to summarize:\n",
        "        {content[:800]}  # Limit input content\n",
        "\n",
        "        Summary with citation:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.summarizer.invoke([HumanMessage(content=prompt)])\n",
        "        # print(\"response 1: \", response.content)\n",
        "\n",
        "        return response.content\n",
        "\n",
        "    def llm2_reasoner(self, query: str, content: str, metadata: Dict, length_control: str) -> str:\n",
        "        \"\"\"LLM 2: Reasoner with deep analysis\"\"\"\n",
        "        citation = self.create_citation(metadata)\n",
        "\n",
        "        length_instructions = {\n",
        "            \"short\": \"Provide reasoning in exactly 2-3 sentences\",\n",
        "            \"medium\": \"Provide reasoning in exactly 4-5 sentences\",\n",
        "            \"long\": \"Provide reasoning in exactly 1-2 paragraphs\"\n",
        "        }\n",
        "\n",
        "        length_instruction = length_instructions.get(length_control, length_instructions[\"short\"])\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are LLM Agent 2 - Medical Reasoning Expert.\n",
        "\n",
        "        Task: Analyze content and provide medical reasoning for the user's query.\n",
        "\n",
        "        CRITICAL RULES:\n",
        "        1. {length_instruction}\n",
        "        2. Always end with this exact citation: {citation}\n",
        "        3. Focus on WHY and HOW aspects\n",
        "        4. Connect information to the user's specific query\n",
        "        5. Must include Citation in the given format at the end\n",
        "\n",
        "        User Query: {query}\n",
        "        Content: {content[:800]}\n",
        "\n",
        "        Medical reasoning with citation:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.reasoner.invoke([HumanMessage(content=prompt)])\n",
        "        # print(\"response 2: \", response.content)\n",
        "        return response.content\n",
        "\n",
        "    def llm3_stylist(self, content: str, metadata: Dict, length_control: str) -> str:\n",
        "        \"\"\"LLM 3: Stylist for final formatting\"\"\"\n",
        "        citation = self.create_citation(metadata)\n",
        "\n",
        "        length_instructions = {\n",
        "            \"short\": \"Format in exactly 2-3 clear, readable sentences\",\n",
        "            \"medium\": \"Format in exactly 1 well-structured paragraph\",\n",
        "            \"long\": \"Format in exactly 2 well-structured paragraphs\"\n",
        "        }\n",
        "\n",
        "        length_instruction = length_instructions.get(length_control, length_instructions[\"short\"])\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are LLM Agent 3 - Content Stylist.\n",
        "\n",
        "        Task: Reformat content to be clear and professional.\n",
        "\n",
        "        CRITICAL RULES:\n",
        "        1. {length_instruction}\n",
        "        2. Preserve all medical information\n",
        "        3. Make text easy to read and understand\n",
        "        4. Always end with this exact citation: {citation}\n",
        "\n",
        "        Content to style:\n",
        "        {content}\n",
        "\n",
        "        Styled content with citation:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.stylist.invoke([HumanMessage(content=prompt)])\n",
        "        # print(\"response 3: \", response.content)\n",
        "\n",
        "        return response.content"
      ],
      "metadata": {
        "id": "jCxhSBficDQe"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    messages: List[BaseMessage]\n",
        "    retrieved_docs: List[Dict]\n",
        "    llm1_outputs: List[str]\n",
        "    llm2_outputs: List[str]\n",
        "    llm3_outputs: List[str]\n",
        "    final_response: str\n",
        "    query: str\n",
        "    length_control: str\n",
        "    namespace: str"
      ],
      "metadata": {
        "id": "YJNpMSTUb8Yt"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgenticAISystem:\n",
        "    def __init__(self, pinecone_api_key: str, groq_api_key: str):\n",
        "        self.pinecone_retriever = PineconeRetriever(pinecone_api_key)\n",
        "        self.setup_graph()\n",
        "\n",
        "    def setup_graph(self):\n",
        "        \"\"\"Setup LangGraph workflow\"\"\"\n",
        "\n",
        "        def retrieve_node(state: State):\n",
        "            \"\"\"Node 1: Retrieve from Pinecone\"\"\"\n",
        "            query = state[\"query\"]\n",
        "            retrieved_docs = self.pinecone_retriever.retrieve_data(\n",
        "                index_name=state.get(\"index_name\", \"alphawell\"),\n",
        "                namespace=state.get(\"namespace\", \"__default__\"),\n",
        "                query=query,\n",
        "                top_k=3  # Limit docs for content control\n",
        "            )\n",
        "            return {\"retrieved_docs\": retrieved_docs}\n",
        "\n",
        "        def multi_llm_processing_node(state: State):\n",
        "            \"\"\"Node 2: Process through all 3 LLMs\"\"\"\n",
        "            if not GROQ_API_KEY:\n",
        "                return {\"llm1_outputs\": [], \"llm2_outputs\": [], \"llm3_outputs\": []}\n",
        "\n",
        "            multi_llm = MultiAgentLLMSystem(GROQ_API_KEY, {})\n",
        "\n",
        "            query = state[\"query\"]\n",
        "            length_control = state.get(\"length_control\", \"short\")\n",
        "            retrieved_docs = state.get(\"retrieved_docs\", [])\n",
        "\n",
        "            print(\"Retrieveed docs from Pinecone: \", retrieved_docs)\n",
        "\n",
        "            llm1_outputs = []\n",
        "            llm2_outputs = []\n",
        "            llm3_outputs = []\n",
        "\n",
        "            # Process each document through all 3 LLMs\n",
        "            for doc in retrieved_docs[:2]:  # Limit to top 2 docs for control\n",
        "                if doc.get('content'):\n",
        "                    # LLM 1: Summarize\n",
        "                    summary = multi_llm.llm1_summarizer(\n",
        "                        doc['content'], doc, length_control\n",
        "                    )\n",
        "                    llm1_outputs.append(summary)\n",
        "\n",
        "                    # LLM 2: Reason\n",
        "                    reasoning = multi_llm.llm2_reasoner(\n",
        "                        query, doc['content'], doc, length_control\n",
        "                    )\n",
        "                    llm2_outputs.append(reasoning)\n",
        "\n",
        "                    # LLM 3: Style the combined content\n",
        "                    combined = f\"Summary: {summary}\\nReasoning: {reasoning}\"\n",
        "                    styled = multi_llm.llm3_stylist(\n",
        "                        combined, doc, length_control\n",
        "                    )\n",
        "                    llm3_outputs.append(styled)\n",
        "\n",
        "            return {\n",
        "                \"llm1_outputs\": llm1_outputs,\n",
        "                \"llm2_outputs\": llm2_outputs,\n",
        "                \"llm3_outputs\": llm3_outputs\n",
        "            }\n",
        "\n",
        "        def main_agent_node(state: State):\n",
        "            \"\"\"Node 3: Main Agent combines everything\"\"\"\n",
        "            query = state[\"query\"]\n",
        "\n",
        "            # Check for general conversation\n",
        "            medical_keywords = ['medicine', 'drug', 'dose', 'side effect', 'treatment', 'cure', 'symptom', 'warning']\n",
        "            is_medical = any(keyword in query.lower() for keyword in medical_keywords)\n",
        "\n",
        "            if not is_medical:\n",
        "                main_llm = ChatGroq(model=\"llama3-8b-8192\", api_key=GROQ_API_KEY, temperature=0.3)\n",
        "                response = main_llm.invoke([\n",
        "                    SystemMessage(content=\"You are a friendly AI assistant. Keep responses brief and natural.\"),\n",
        "                    HumanMessage(content=query)\n",
        "                ])\n",
        "                return {\"final_response\": response.content}\n",
        "\n",
        "            # Medical query - combine all LLM outputs\n",
        "            llm3_outputs = state.get(\"llm3_outputs\", [])\n",
        "\n",
        "            if not llm3_outputs:\n",
        "                return {\"final_response\": \"I don't have specific information about that in my medical database. Please consult a healthcare professional.\"}\n",
        "\n",
        "            length_control = state.get(\"length_control\", \"short\")\n",
        "\n",
        "            length_instructions = {\n",
        "                \"short\": \"Provide final answer in exactly 3-4 sentences total\",\n",
        "                \"medium\": \"Provide final answer in exactly 1-2 paragraphs\",\n",
        "                \"long\": \"Provide final answer in exactly 2-3 paragraphs\"\n",
        "            }\n",
        "\n",
        "            length_instruction = length_instructions.get(length_control, length_instructions[\"short\"])\n",
        "\n",
        "            combined_content = \"\\n\\n\".join(llm3_outputs)\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You are the Main AI Agent coordinating medical information.\n",
        "\n",
        "            Task: Provide comprehensive answer based on processed information from 3 specialist LLMs.\n",
        "\n",
        "            CRITICAL RULES:\n",
        "            1. {length_instruction}\n",
        "            2. Preserve ALL citations from the content\n",
        "            3. Combine information logically\n",
        "            4. Ensure medical accuracy\n",
        "            5. Answer directly addresses user's query\n",
        "            6. Strictly include Citation in the given format at the end\n",
        "\n",
        "            User Query: {query}\n",
        "            Processed Content from LLM Agents:\n",
        "            {combined_content}\n",
        "\n",
        "            Final comprehensive answer:\n",
        "            Citation: [PDF: , Page No: , Topic: ]\n",
        "            \"\"\"\n",
        "\n",
        "            main_llm = ChatGroq(model=\"llama3-70b-8192\", api_key=GROQ_API_KEY, temperature=0.1)\n",
        "            response = main_llm.invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "            # print(\"response 4: \", response.content)\n",
        "\n",
        "            return {\"final_response\": response.content}\n",
        "\n",
        "        # Build the graph\n",
        "        builder = StateGraph(State)\n",
        "        builder.add_node(\"retrieve\", retrieve_node)\n",
        "        builder.add_node(\"process_llms\", multi_llm_processing_node)\n",
        "        builder.add_node(\"main_agent\", main_agent_node)\n",
        "\n",
        "        # Add edges\n",
        "        builder.add_edge(START, \"retrieve\")\n",
        "        builder.add_edge(\"retrieve\", \"process_llms\")\n",
        "        builder.add_edge(\"process_llms\", \"main_agent\")\n",
        "        builder.add_edge(\"main_agent\", END)\n",
        "\n",
        "        self.graph = builder.compile()\n",
        "\n",
        "    def process_query(self, index_name: str, namespace: str, query: str, length: str = \"short\") -> str:\n",
        "        \"\"\"Process query through multi-agent system\"\"\"\n",
        "        initial_state = {\n",
        "            \"messages\": [HumanMessage(content=query)],\n",
        "            \"retrieved_docs\": [],\n",
        "            \"llm1_outputs\": [],\n",
        "            \"llm2_outputs\": [],\n",
        "            \"llm3_outputs\": [],\n",
        "            \"final_response\": \"\",\n",
        "            \"query\": query,\n",
        "            \"length_control\": length,\n",
        "            \"index_name\": index_name,\n",
        "            \"namespace\": namespace\n",
        "        }\n",
        "\n",
        "        final_state = self.graph.invoke(initial_state)\n",
        "        return final_state.get(\"final_response\", \"Unable to process query.\")"
      ],
      "metadata": {
        "id": "C0X8I02Vam64"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agenticAI(index_name: str, namespace: str, query: str, length: str = \"short\") -> str:\n",
        "    if not PINECONE_API_KEY:\n",
        "        return \"Please set PINECONE_API_KEY\"\n",
        "    if not GROQ_API_KEY:\n",
        "        return \"Please set GROQ_API_KEY\"\n",
        "\n",
        "    try:\n",
        "        ai_system = AgenticAISystem(PINECONE_API_KEY, GROQ_API_KEY)\n",
        "        # print(\"given: \", namespace)\n",
        "        return ai_system.process_query(index_name, namespace, query, length)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "gQnUDbYwPbju"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Multi-Agent Agentic AI System Ready!\")\n",
        "\n",
        "result = agenticAI('alphawell', '94uo6WQUnIV9izlJrRBsXXX2025-08-26_18-55-24', \"what is Hematological Reactions?\", \"large\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWYp_svQ0Vc2",
        "outputId": "95ec96a6-f3a9-415c-e338-150a2760610f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-Agent Agentic AI System Ready!\n",
            "Retrieving from the index alphawell and namespace 94uo6WQUnIV9izlJrRBsXXX2025-08-26_18-55-24\n",
            "Retrieveed docs from Pinecone:  [{'id': '94uo6WQUnIV9izlJrRBs_4de2c0cafb6470b55779', 'score': 0.441521734, 'content': 'medicine: highlights of prescribing information - topic: use in specific populations - context: (5.5) ]  hematological reactions [see', 'file_name': 'humira.pdf', 'page': 0.0, 'topic': 'use in specific populations', 'name': 'highlights of prescribing information'}, {'id': '94uo6WQUnIV9izlJrRBs_51835a2ad38dfb057976', 'score': 0.369448453, 'content': 'medicine: highlights of prescribing information - topic: other - context: rare reports of pancytopenia including aplastic anemia have been reported with tnf blocking agents. adverse reactions of the hematologic system, including medically significant cytopenia (e.g., thrombocytopenia, leukopenia) have been infrequently reported with humira. the causal relationship of these reports to humira remains unclear. advise all patients to seek immediate medical attention if they develop signs and symptoms suggestive of blood dyscrasias or infection (e.g., persistent fever, bruising, bleeding, pallor) while on humira. consider discontinuation of humira therapy in patients with confirmed significant hematologic abnormalities.', 'file_name': 'humira.pdf', 'page': 13.0, 'topic': 'other', 'name': 'highlights of prescribing information'}, {'id': '94uo6WQUnIV9izlJrRBs_b7af62a90866db6d0f59', 'score': 0.352860719, 'content': 'medicine: highlights of prescribing information - topic: other - context: hemic and lymphatic system: agranulocytosis, polycythemia', 'file_name': 'humira.pdf', 'page': 18.0, 'topic': 'other', 'name': 'highlights of prescribing information'}]\n",
            "Hematological reactions refer to adverse reactions that occur in the blood or blood-forming organs, such as anemia, bleeding disorders, or blood clotting abnormalities. These reactions can be caused by various factors, including medications, infections, or autoimmune disorders. Common examples of hematological reactions include:\n",
            "\n",
            "* Anemia\n",
            "* Leukopenia (low white blood cell count)\n",
            "* Thrombocytopenia (low platelet count)\n",
            "* Bleeding disorders, such as hemophilia\n",
            "* Blood clotting abnormalities, such as disseminated intravascular coagulation (DIC)\n",
            "\n",
            "If you're experiencing any unusual symptoms or concerns about your blood health, it's always best to consult with a healthcare professional for proper evaluation and treatment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, UploadFile, File, Form\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "# import pinecone\n",
        "# from langchain.vectorstores import Pinecone\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "origins=[\"*\"]\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"]\n",
        ")\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    request: str\n",
        "    namespace: str\n",
        "\n",
        "# Agentic AI\n",
        "@app.post(\"/alpha_bot80\")\n",
        "async def respond(data: QueryRequest):\n",
        "    print(\"User Query:\", data.request)\n",
        "    # print(\"Namespace:\", data.namespace)\n",
        "    answer = agenticAI('alphawell', data.namespace, data.request, \"large\")\n",
        "    return {\"answer\": answer}"
      ],
      "metadata": {
        "id": "mIyjhF68uLZ2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "!ngrok authtoken $ngrok_token\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(\"Public URL\", ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9oruHrEZ4iq",
        "outputId": "eff783f4-387c-4068-cfdc-f7c1a4025359"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Public URL https://72f6d1313fc6.ngrok-free.app\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [26610]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2401:4900:889f:3b70:2cb0:7f49:8e26:7dea:0 - \"OPTIONS /alpha_bot80 HTTP/1.1\" 200 OK\n",
            "User Query: [user] hi i am gokul\n",
            "[assistant]  Processing...\n",
            "[user] \n",
            "Retrieving from the index alphawell and namespace P8OVDfZGhfAZzsIzOb57XXX2025-08-26_21-20-27\n",
            "Retrieveed docs from Pinecone:  [{'id': 'P8OVDfZGhfAZzsIzOb57_69535e1276dc64eb6e5b', 'score': 0.12847425, 'content': 'medicine: highlights of prescribing information - topic: interactions - context: with dayvigo 8', 'file_name': 'davigo.pdf', 'page': 0.0, 'topic': 'interactions', 'name': 'highlights of prescribing information'}, {'id': 'P8OVDfZGhfAZzsIzOb57_2eeac71c3b6a1baf275e', 'score': 0.126646057, 'content': 'medicine: highlights of prescribing information - topic: other - context: distributed by: eisai inc. woodcliff lake, nj 07677 dayvigo tm is a trademark of eisai r&d management co., ltd. and is licensed to eisai inc.', 'file_name': 'davigo.pdf', 'page': 20.0, 'topic': 'other', 'name': 'highlights of prescribing information'}, {'id': 'P8OVDfZGhfAZzsIzOb57_9731e95bf21982650186', 'score': 0.120660789, 'content': 'medicine: highlights of prescribing information - topic: other - context: dayvigo tm is a trademark of eisai r&d management co., ltd. and is licensed to eisai inc.  xxxx eisai inc. for more information, go to www.dayvigo.com or call 1-888-274-2378 this medication guide has been approved by the u.s. food and drug administration. issued: 12/2019', 'file_name': 'davigo.pdf', 'page': 22.0, 'topic': 'other', 'name': 'highlights of prescribing information'}]\n",
            "INFO:     2401:4900:889f:3b70:2cb0:7f49:8e26:7dea:0 - \"POST /alpha_bot80 HTTP/1.1\" 200 OK\n",
            "User Query: [user] hi i am gokul\n",
            "[assistant] Nice to meet you, Gokul! How can I help you today? \n",
            "[user] what is the most common adverse reaction of using this medicine?\n",
            "[assistant]  Processing...\n",
            "[user] \n",
            "Retrieving from the index alphawell and namespace P8OVDfZGhfAZzsIzOb57XXX2025-08-26_21-20-27\n",
            "Retrieveed docs from Pinecone:  [{'id': 'P8OVDfZGhfAZzsIzOb57_b1e258dd30b70fa1a6de', 'score': 0.459909141, 'content': 'medicine: highlights of prescribing information - topic: adverse - context: ------------------------', 'file_name': 'davigo.pdf', 'page': 1.0, 'topic': 'adverse', 'name': 'highlights of prescribing information'}, {'id': 'P8OVDfZGhfAZzsIzOb57_43aab50fe619f8b17504', 'score': 0.441605061, 'content': 'medicine: highlights of prescribing information - topic: other - context: other adverse reactions of <2% incidence but greater than placebo are shown below. the following list does not include adverse reactions 1) for which a drug cause was remote, 2) that were so general to be uninformative, or 3) that were not considered to have clinically significant implications.', 'file_name': 'davigo.pdf', 'page': 6.0, 'topic': 'other', 'name': 'highlights of prescribing information'}, {'id': 'P8OVDfZGhfAZzsIzOb57_13a8ab2045032f14fb2f', 'score': 0.432035416, 'content': 'medicine: highlights of prescribing information - topic: other - context: adverse reactions resulting in discontinuation of treatment', 'file_name': 'davigo.pdf', 'page': 5.0, 'topic': 'other', 'name': 'highlights of prescribing information'}]\n",
            "INFO:     2401:4900:889f:3b70:2cb0:7f49:8e26:7dea:0 - \"POST /alpha_bot80 HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dDVRlguuaEhZ"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}